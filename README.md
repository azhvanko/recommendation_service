# Recommendation service

Микросервис для генерации рекомендаций на основе истории действий пользователей. Реализован с использованием **FastAPI** и колоночной базы данных **ClickHouse**.

## Запуск

Для запуска требуется установленный **Docker** и **Docker Compose**.

### 1. Запуск сервиса
```bash
# Сборка и запуск контейнеров
make up
# Остановка контейнеров
make down
# Полная очистка
make clear
```
После запуска документация API доступна по адресу: [Swagger UI](http://localhost:8080/api/docs)

### 2. Загрузка тестовых данных
Чтобы загрузить тестовый датасет в формате `csv`, выполните команду:

```bash
# Загружает данные из файла data/test.csv в ClickHouse
make insert_user_events
```

---

## Архитектура решения

Стек выбран для обеспечения максимальной производительности при работе с аналитическими данными:

1. ClickHouse: Колоночная база данных хорошо подходит для хранения логов событий и мгновенного расчета агрегаций на больших объемах данных.
2. FastAPI: Полностью асинхронный I/O позволяет эффективно обрабатывать конкурентные запросы, не блокируя поток выполнения.
3. SQL-first подход: Вся тяжелая логика фильтрации выполняется на стороне БД. Это минимизируя передачу данных по сети и нагрузку на CPU приложения.

---

## Рекомендации по эксплуатации в production среде

Для обеспечения высокой доступности и масштабируемости рекомендуется внедрить следующие решения:

1. Оркестрация (Kubernetes)
   * Масштабирование сервиса лучше привязать не к потреблению CPU (которое у асинхронного FastAPI может быть низким даже под нагрузкой), а к реальным метрикам — RPS или Latency.
   * Чтобы падение одного физического сервера не остановило работу сервиса, стоит настроить Anti-Affinity, распределив реплики приложения по разным нодам.
2. Сетевой слой (Nginx / Ingress)
    * Важно настроить Upstream Keep-Alive. Это позволит переиспользовать TCP-соединения между балансировщиком и приложением, снижая задержки и нагрузку на сервис.
    * Для ускорения API стоит включить HTTP/2 и сжатие ответов (Gzip или Brotli).
3. База данных (ClickHouse)
   * Для отказоустойчивости ClickHouse стоит разворачивать минимум в 2 репликах на разных нодах (с использованием ClickHouse Keeper) и перейти с локального движка MergeTree на кластерный ReplicatedMergeTree.
   * Необходимо организовать потоковую вставку данных через Kafka/RabbitMQ. Это позволит обновлять рекомендации в режиме реального времени.
4. Кэширование (Redis)
   * Чтобы снизить нагрузку на ClickHouse, результаты тяжелых агрегаций (например, глобальный топ товаров или выдачу для активных пользователей) стоит кэшировать в Redis с небольшим TTL (5–10 минут).
